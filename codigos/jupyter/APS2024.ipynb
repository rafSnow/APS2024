{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac78776-79d0-4daa-9a07-fe9a959ea9ca",
   "metadata": {},
   "source": [
    "# Atividades Práticas Supervisionadas(APS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd47b8e9-fb2e-4cd1-b336-b9c73002edf4",
   "metadata": {},
   "source": [
    "### Importando Bibiotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f71146-bd84-4800-b450-f5fc3bf838fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafael.nsouza\\AppData\\Local\\anaconda3\\envs\\aps\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4ab39-5e72-4c79-b7cc-f46dc267aa53",
   "metadata": {},
   "source": [
    "## Pré-processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909fa4a5-2d31-427b-a8b2-509506e3f564",
   "metadata": {},
   "source": [
    "### Funções para limpar os textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a34964f-3f5c-402e-92d6-71517c467c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(instancia):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "def Stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras = []\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "def Limpeza_dados(instancia):\n",
    "    # Remover links\n",
    "    instancia = re.sub(r'http\\S+', '', instancia)\n",
    "    # Remover menções a usuários\n",
    "    instancia = re.sub(r'@\\w+', '', instancia)\n",
    "    # Remover caracteres especiais e números\n",
    "    instancia = re.sub(r'[^a-zA-Z\\s]', '', instancia)\n",
    "    # Remover espaços extras\n",
    "    instancia = re.sub(r'\\s+', ' ', instancia)\n",
    "    return instancia.strip()\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def Lemmatization(instancia):\n",
    "  palavras = []\n",
    "  for w in instancia.split():\n",
    "    palavras.append(wordnet_lemmatizer.lemmatize(w))\n",
    "  return (\" \".join(palavras))\n",
    "\n",
    "def Preprocessing(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc0d585-c185-484c-98db-829b25938154",
   "metadata": {},
   "source": [
    "### Carregar dados do arquivo e limpar os Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e140df2-59da-4d24-b939-18f05b826060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafael.nsouza\\AppData\\Local\\Temp\\ipykernel_7844\\4034209713.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"Classificacao\"] = df[\"Classificacao\"].replace({'Negativo': 0, 'Positivo': 1})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tweets após a remoção: 3798\n",
      "Número de rótulos após a remoção: 3798\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/Tweets_Mg.csv\")\n",
    "df = df[[\"Text\", \"Classificacao\"]]\n",
    "\n",
    "df = df[df['Classificacao'] != 'Neutro']\n",
    "df[\"Classificacao\"] = df[\"Classificacao\"].replace({'Negativo': 0, 'Positivo': 1})\n",
    "df.drop_duplicates(['Text'], inplace=True)\n",
    "tweets = df['Text'].apply(Limpeza_dados)\n",
    "tweets = [Preprocessing(i) for i in tweets]\n",
    "classes = df['Classificacao']\n",
    "\n",
    "print(\"Número de tweets após a remoção:\", len(tweets))\n",
    "print(\"Número de rótulos após a remoção:\", len(classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a562c9-6d68-47c5-8e9e-e522377556e0",
   "metadata": {},
   "source": [
    "## Treinando o Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2b0a4-c2af-4909-86f3-d91f1df0ae2b",
   "metadata": {},
   "source": [
    "### Carregar o tokenizer e o modelo pré-treinado BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958d1497-5d9c-4ab1-b339-358256032b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb5fbe-4368-4da0-92d5-2acfde736fbd",
   "metadata": {},
   "source": [
    "### Conjunto de dados de Treinamento Adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7ebe2c-a198-4ef5-84bc-459f72d28845",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = tweets\n",
    "train_labels = torch.tensor(classes.tolist())  # 1 para positivo, 0 para negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f1cb2-4860-4ab7-bae5-71915c4f9615",
   "metadata": {},
   "source": [
    "### Tokenizar os dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6601c4b-be3e-4893-99bd-d96b5fce9be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dict = tokenizer(train_sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids = encoded_dict['input_ids']\n",
    "attention_mask = encoded_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07beb87d-5173-4f99-aec8-59ee409affee",
   "metadata": {},
   "source": [
    "### Criar o conjunto de dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071a227f-b9a2-447e-b14e-7064baff430e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3798\n",
      "3798\n",
      "3798\n"
     ]
    }
   ],
   "source": [
    "print(len(input_ids))\n",
    "print(len(attention_mask))\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e11b53-e4c2-4404-9f02-f38d479c7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids, attention_mask, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bfbf52-80f8-4e7e-8435-50500f9de80b",
   "metadata": {},
   "source": [
    "### Definir hiperparâmetros de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b16314-5b2e-4cfe-bc0a-ac24670658bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 2e-5\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd7db4-4a20-47e8-9e18-faec8ff29d9c",
   "metadata": {},
   "source": [
    "### Criar o DataLoader para o conjunto de dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1bae8f8-e30c-4b8b-aca5-edb0076a36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f802b-6041-483a-9d0a-45f22df8c2ee",
   "metadata": {},
   "source": [
    "### Configurar otimizador e função de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2783be42-5ae0-4099-a1b7-62788f884dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafael.nsouza\\AppData\\Local\\anaconda3\\envs\\aps\\lib\\site-packages\\transformers\\optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5974da-1542-456d-9a4e-67769bc8fd41",
   "metadata": {},
   "source": [
    "### Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e9577-3edf-44d8-b812-54429ffe0c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Epoch 1/20, Loss: 19.03742466121912\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Epoch 2/20, Loss: 21.95818355679512\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Epoch 3/20, Loss: 20.39417166262865\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Epoch 4/20, Loss: 17.53788362443447\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Epoch 5/20, Loss: 21.228616192936897\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Epoch 6/20, Loss: 17.90257538855076\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Epoch 7/20, Loss: 20.75567853450775\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Epoch 8/20, Loss: 16.556241810321808\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Epoch 9/20, Loss: 20.727863878011703\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print('0')\n",
    "for epoch in range(epochs):\n",
    "    print('1')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        print('2')\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e77f44-7487-42be-b665-f25959fb637b",
   "metadata": {},
   "source": [
    "### Salvar o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f63eae-5ff2-4b50-a879-aae94dfc2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_file = \"sentiment_model.bin\"\n",
    "torch.save(model.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caf2260-a38f-433d-8d6b-6fce2e569f0f",
   "metadata": {},
   "source": [
    "## Carregar o modelo pré-treinado BERT para análise de sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172de4b0-bdbc-49fa-95cf-62b0ac157ec5",
   "metadata": {},
   "source": [
    "### Carregar os pesos do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93123d-3ea5-4e89-b5c1-784537c300a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"sentiment_model.bin\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a7782-8106-45b7-911d-21f518907b86",
   "metadata": {},
   "source": [
    "### Frases de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55830d-f3ca-4827-ae33-600d9134407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"A trama deste filme é envolvente.\",\n",
    "    \"O desfecho deste livro me surpreendeu.\",\n",
    "    \"As sobremesas deste restaurante são divinas.\",\n",
    "    \"Este filme é um clássico!\",\n",
    "    \"O enredo deste livro é cativante.\",\n",
    "    \"A comida neste café é de dar água na boca.\",\n",
    "    \"Este restaurante sempre me impressiona com seus pratos.\",\n",
    "    \"O roteiro deste filme é impecável.\",\n",
    "    \"Este livro me emocionou do começo ao fim.\",\n",
    "    \"Os pratos deste restaurante são uma explosão de sabores.\",\n",
    "    \"A atuação neste filme é excepcional.\",\n",
    "    \"Este livro é uma obra-prima.\",\n",
    "    \"A experiência neste restaurante é única.\",\n",
    "    \"Os personagens deste filme são muito bem desenvolvidos.\",\n",
    "    \"O autor deste livro tem uma escrita cativante.\",\n",
    "    \"A atmosfera deste restaurante é acolhedora.\",\n",
    "    \"Este filme me fez refletir sobre muitas coisas.\",\n",
    "    \"Este livro é uma verdadeira viagem.\",\n",
    "    \"As críticas deste filme são merecidas.\",\n",
    "    \"O final deste livro me deixou sem palavras.\",\n",
    "    \"Este restaurante é uma excelente escolha para ocasiões especiais.\",\n",
    "    \"Os efeitos especiais neste filme são impressionantes.\",\n",
    "    \"Este livro é uma leitura obrigatória.\",\n",
    "    \"A decoração deste restaurante é encantadora.\",\n",
    "    \"A trilha sonora deste filme é incrível.\",\n",
    "    \"Este livro me prendeu do início ao fim.\",\n",
    "    \"A apresentação dos pratos neste restaurante é impecável.\",\n",
    "    \"A mensagem deste filme é poderosa.\",\n",
    "    \"Este livro me fez repensar muitas coisas.\",\n",
    "    \"A comida neste restaurante é de outro mundo.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca012b-0f2d-4708-b1a7-be107153ca7f",
   "metadata": {},
   "source": [
    "### Tokenizar as frases de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb6187-dc19-48bb-ba0c-ae5d0547d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dict = tokenizer(test_sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids = encoded_dict['input_ids']\n",
    "attention_mask = encoded_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca01d9-75da-40aa-bcf1-a0eae1e38608",
   "metadata": {},
   "source": [
    "### Realizar as previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a490b0-e768-475b-86f6-a9ab4111f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f4b9f-c60a-4762-a305-964caed44b77",
   "metadata": {},
   "source": [
    "### Mapear as previsões de volta para rótulos de sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2ad9f-79ac-49f5-89cd-82bd2e9f4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(logits, dim=1)\n",
    "sentiment_labels = ['Positivo' if pred == 1 else 'Negativo' for pred in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0c1ee-cc06-4353-98ad-8ebaa7466f20",
   "metadata": {},
   "source": [
    "### Exibir os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ca4ef-9df4-41a0-b552-c2b0d69c2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, sentiment in zip(test_sentences, sentiment_labels):\n",
    "    print(f\"Frase: {sentence}\")\n",
    "    print(f\"Sentimento: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297886d1-e43c-4b4b-871c-b98b17ded5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aps",
   "language": "python",
   "name": "aps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
