{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82528038-dcd0-4517-b78c-ac61535c8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1277be5-e082-4a68-b168-d02e25d4c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "column_names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "df = pd.read_csv(r\"..\\data\\training.1600000.processed.noemoticon.csv\", encoding=\"ISO-8859-1\", names=column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e017d252-f402-4f00-b72e-5b24c360097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento dos dados\n",
    "df = df[[\"target\", \"text\"]]  # Mantém apenas as colunas necessárias\n",
    "df[\"target\"] = df[\"target\"].replace({0: 0, 4: 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1450d487-baf3-47df-b966-f5e44562c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização e Vetorização\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df[\"text\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"text\"])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed5c023-a32d-4f8f-83c0-d22bee0afd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df[\"target\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc9858bf-747b-4412-8372-b56afaf284fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo RNN\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=16),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f60c1a6-8ce5-4a75-8010-a675aead7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c132df4-0c4a-4a1d-8452-191646158da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m775s\u001b[0m 77ms/step - accuracy: 0.7770 - loss: 0.4697 - val_accuracy: 0.8156 - val_loss: 0.4037\n",
      "Epoch 2/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m804s\u001b[0m 80ms/step - accuracy: 0.8162 - loss: 0.4066 - val_accuracy: 0.8195 - val_loss: 0.3964\n",
      "Epoch 3/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m828s\u001b[0m 83ms/step - accuracy: 0.8223 - loss: 0.3954 - val_accuracy: 0.8232 - val_loss: 0.3884\n",
      "Epoch 4/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 84ms/step - accuracy: 0.8260 - loss: 0.3875 - val_accuracy: 0.8244 - val_loss: 0.3873\n",
      "Epoch 5/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m844s\u001b[0m 84ms/step - accuracy: 0.8291 - loss: 0.3826 - val_accuracy: 0.8254 - val_loss: 0.3859\n",
      "Epoch 6/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 84ms/step - accuracy: 0.8310 - loss: 0.3783 - val_accuracy: 0.8267 - val_loss: 0.3839\n",
      "Epoch 7/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m844s\u001b[0m 84ms/step - accuracy: 0.8325 - loss: 0.3750 - val_accuracy: 0.8266 - val_loss: 0.3854\n",
      "Epoch 8/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m858s\u001b[0m 86ms/step - accuracy: 0.8342 - loss: 0.3714 - val_accuracy: 0.8279 - val_loss: 0.3811\n",
      "Epoch 9/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m862s\u001b[0m 86ms/step - accuracy: 0.8368 - loss: 0.3676 - val_accuracy: 0.8282 - val_loss: 0.3801\n",
      "Epoch 10/10\n",
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m861s\u001b[0m 86ms/step - accuracy: 0.8378 - loss: 0.3663 - val_accuracy: 0.8286 - val_loss: 0.3813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18ef6276cb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ea3a6e-22dd-4865-9086-ef12905d0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10000/10000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 14ms/step - accuracy: 0.8285 - loss: 0.3805\n",
      "Acurácia do modelo nos dados de teste: 0.8286499977111816\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Acurácia do modelo nos dados de teste:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7daf26a0-718f-464a-b4ab-9bcf11fc881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo treinado e tokenizer salvos com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Salvar o modelo e o tokenizer\n",
    "model.save(r\"..\\modelos\\modelo_rnn.keras\")\n",
    "with open(r\"..\\modelos\\tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Modelo treinado e tokenizer salvos com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fae618-16a6-4485-938f-1161291cf830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aps",
   "language": "python",
   "name": "aps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
