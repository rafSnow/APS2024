{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82528038-dcd0-4517-b78c-ac61535c8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1277be5-e082-4a68-b168-d02e25d4c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "df = pd.read_csv(r'..\\..\\data\\Tweets_Mg.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e017d252-f402-4f00-b72e-5b24c360097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafael.nsouza\\AppData\\Local\\Temp\\ipykernel_16800\\3037184820.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[\"Classificacao\"] = df[\"Classificacao\"].replace({'Negativo': 0, 'Positivo': 1, 'Neutro' : 2})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>���⛪ @ Catedral de Santo Antônio - Governador ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>� @ Governador Valadares, Minas Gerais https:/...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>�� @ Governador Valadares, Minas Gerais https:...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>��� https://t.co/BnDsO34qK0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>��� PSOL vai questionar aumento de vereadores ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Classificacao\n",
       "0  ���⛪ @ Catedral de Santo Antônio - Governador ...              2\n",
       "1  � @ Governador Valadares, Minas Gerais https:/...              2\n",
       "2  �� @ Governador Valadares, Minas Gerais https:...              2\n",
       "3                        ��� https://t.co/BnDsO34qK0              2\n",
       "4  ��� PSOL vai questionar aumento de vereadores ...              0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pré-processamento dos dados\n",
    "df = df[[\"Text\", \"Classificacao\"]]  # Mantém apenas as colunas necessárias\n",
    "df[\"Classificacao\"] = df[\"Classificacao\"].replace({'Negativo': 0, 'Positivo': 1, 'Neutro' : 2})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1450d487-baf3-47df-b966-f5e44562c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização e Vetorização\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df[\"Text\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"Text\"])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed5c023-a32d-4f8f-83c0-d22bee0afd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, df[\"Classificacao\"], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc9858bf-747b-4412-8372-b56afaf284fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção do modelo RNN\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=16),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f60c1a6-8ce5-4a75-8010-a675aead7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilação do modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c132df4-0c4a-4a1d-8452-191646158da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 100ms/step - accuracy: 0.4077 - loss: 0.3396 - val_accuracy: 0.4030 - val_loss: -0.3763\n",
      "Epoch 2/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.4929 - loss: -2.1015 - val_accuracy: 0.6476 - val_loss: -18.2630\n",
      "Epoch 3/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6404 - loss: -23.8340 - val_accuracy: 0.6500 - val_loss: -58.8776\n",
      "Epoch 4/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6456 - loss: -66.5308 - val_accuracy: 0.6683 - val_loss: -105.8900\n",
      "Epoch 5/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6644 - loss: -112.6818 - val_accuracy: 0.6683 - val_loss: -176.9559\n",
      "Epoch 6/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.6683 - loss: -190.6640 - val_accuracy: 0.6720 - val_loss: -271.2330\n",
      "Epoch 7/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6780 - loss: -285.7560 - val_accuracy: 0.6683 - val_loss: -373.8411\n",
      "Epoch 8/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.6874 - loss: -364.5554 - val_accuracy: 0.6726 - val_loss: -489.7158\n",
      "Epoch 9/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.6747 - loss: -493.4893 - val_accuracy: 0.6726 - val_loss: -608.4647\n",
      "Epoch 10/10\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6639 - loss: -625.1972 - val_accuracy: 0.6762 - val_loss: -731.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x159ec2dd5a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinamento do modelo\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35ea3a6e-22dd-4865-9086-ef12905d0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6935 - loss: -672.8414\n",
      "Acurácia do modelo nos dados de teste: 0.6762195229530334\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Acurácia do modelo nos dados de teste:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf26a0-718f-464a-b4ab-9bcf11fc881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo e o tokenizer\n",
    "model.save(r\"..\\modelos\\modelo_rnn.keras\")\n",
    "with open(r\"..\\modelos\\tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"Modelo treinado e tokenizer salvos com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3fae618-16a6-4485-938f-1161291cf830",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"O dia está lindo e ensolarado, é um ótimo momento para um passeio no parque.\",\n",
    "    \"Estou muito feliz com o resultado do meu trabalho hoje, me sinto realizado.\",\n",
    "    \"Infelizmente, meu time perdeu o jogo ontem à noite, estou muito desapontado.\",\n",
    "    \"Acabei de assistir a um filme incrível, recomendo a todos!\",\n",
    "    \"O trânsito estava terrível esta manhã, cheguei atrasado no trabalho.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3db6db82-8791-4191-8553-bb33c907f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n"
     ]
    }
   ],
   "source": [
    "# Tokenização das frases\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "padded_test_sequences = pad_sequences(test_sequences, maxlen=100)\n",
    "\n",
    "# Fazendo previsões\n",
    "predictions = model.predict(padded_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4c8712b-c7a6-4b98-bcec-0827b4e8fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arredondando as previsões para obter classes binárias (0 ou 1)\n",
    "binary_predictions = np.round(predictions).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56f18ea8-7dfc-4431-8705-99c4203febd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeando as classes de volta para as strings originais\n",
    "class_mapping = {0: 'Negativo', 1: 'Positivo', 2: 'Neutro'}\n",
    "predicted_classes = [class_mapping[int(pred)] for pred in binary_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9975b879-c811-456b-bee8-1109c6be98e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: O dia está lindo e ensolarado, é um ótimo momento para um passeio no parque.\n",
      "Previsão: Positivo\n",
      "\n",
      "Frase: Estou muito feliz com o resultado do meu trabalho hoje, me sinto realizado.\n",
      "Previsão: Positivo\n",
      "\n",
      "Frase: Infelizmente, meu time perdeu o jogo ontem à noite, estou muito desapontado.\n",
      "Previsão: Positivo\n",
      "\n",
      "Frase: Acabei de assistir a um filme incrível, recomendo a todos!\n",
      "Previsão: Positivo\n",
      "\n",
      "Frase: O trânsito estava terrível esta manhã, cheguei atrasado no trabalho.\n",
      "Previsão: Positivo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exibindo as previsões\n",
    "for sentence, prediction in zip(test_sentences, predicted_classes):\n",
    "    print(f\"Frase: {sentence}\")\n",
    "    print(f\"Previsão: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e9e72-c8f7-422b-8c46-4bde10106aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aps",
   "language": "python",
   "name": "aps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
