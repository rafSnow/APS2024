{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4fe7f3-9da6-4313-aca0-481493a6b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import praw\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868ee45-0652-4325-a932-e8d85e81a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo treinado\n",
    "model = load_model(\"modelo_aps.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973ef80-a28b-43f5-b1b0-f24df1f5efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o tokenizer\n",
    "with open(\"tokenizer.pickle\", \"rb\") as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b67de-4bfc-43d5-8777-c9715f98e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para classificar o sentimento de um texto\n",
    "def classify_sentiment(text, tokenizer, model):\n",
    "    # Tokenização e vetorização\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=100)\n",
    "    # Prever o sentimento usando o modelo treinado\n",
    "    prediction = model.predict(padded_sequence)[0][0]\n",
    "    if prediction >= 0.5:\n",
    "        return \"Positivo\"\n",
    "    else:\n",
    "        return \"Negativo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed914e-7a37-4bba-ac84-0880f842b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para inserir dados no banco de dados\n",
    "def insert_into_db(conn, submission, sentiment):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''INSERT INTO posts (id, title, content, sentiment, subreddit, author, url, score, num_comments, created_utc)\n",
    "                      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',\n",
    "                   (submission.id, submission.title, submission.selftext, sentiment, submission.subreddit, submission.author.name,\n",
    "                    submission.url, submission.score, submission.num_comments, submission.created_utc))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d23c815-4ab8-4d60-9dd5-35ac21d62349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar ao banco de dados SQLite\n",
    "conn = sqlite3.connect(\"reddit_posts.db\")\n",
    "\n",
    "# Criar uma tabela no banco de dados se não existir\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS posts\n",
    "                  (id TEXT PRIMARY KEY, title TEXT, content TEXT, sentiment TEXT, subreddit TEXT, author TEXT,\n",
    "                  url TEXT, score INTEGER, num_comments INTEGER, created_utc INTEGER)''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c838b1-344a-4863-95c7-fdf5f77df7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar as credenciais para acessar a API do Reddit\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"0LUIMHwzq6iTBcF4F4zGpQ\",\n",
    "    client_secret=\"AN90R4CXtXjCpEfXEEVCIKIjReY0NA\",\n",
    "    user_agent=\"aps\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d15545-5a26-43f4-b8a2-c61332131e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de tópicos de interesse\n",
    "topics = [\"deforestation\", \"forestfires\", \"floods\", \"rain\", \"riverpollution\", \"dams\"]\n",
    "\n",
    "# Iterar sobre os posts do Reddit\n",
    "for topic in topics:\n",
    "    for submission in reddit.subreddit(\"all\").search(topic, sort=\"hot\", time_filter=\"week\"):\n",
    "        if submission.selftext.strip() != \"\" or submission.url.strip() != \"\":\n",
    "            # Concatenar o título e o conteúdo do post\n",
    "            text = submission.title + \" \" + submission.selftext\n",
    "            # Classificar o sentimento do texto\n",
    "            sentiment = classify_sentiment(text, tokenizer, model)\n",
    "            # Inserir os dados no banco de dados\n",
    "            insert_into_db(conn, submission, sentiment)\n",
    "\n",
    "# Fechar a conexão com o banco de dados\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aps",
   "language": "python",
   "name": "aps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
